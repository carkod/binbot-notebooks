{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a56774",
   "metadata": {},
   "source": [
    "# Market breadth predictions with N-BEATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d8f563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping darts as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping u8darts as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping u8darts as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (2.7.1)\n",
      "Requirement already satisfied: torch in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (0.22.1)\n",
      "Requirement already satisfied: torchvision in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (0.22.1)\n",
      "Requirement already satisfied: filelock in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from torchvision) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: filelock in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from torchvision) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U torch torchvision\n",
    "%pip install -qU numpy==2.2.0 darts==0.35.0 scipy matplotlib requests scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5769d136",
   "metadata": {},
   "source": [
    "# Final model with covariates total_volume and MAs\n",
    "\n",
    "- Uses 500 epochs (which seems to provide a better fit). Adjust as necessary when running locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f3f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 9.2 M  | train\n",
      "-------------------------------------------------------------\n",
      "9.2 M     Trainable params\n",
      "3.7 K     Non-trainable params\n",
      "9.2 M     Total params\n",
      "36.669    Total estimated model params size (MB)\n",
      "396       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 9.2 M  | train\n",
      "-------------------------------------------------------------\n",
      "9.2 M     Trainable params\n",
      "3.7 K     Non-trainable params\n",
      "9.2 M     Total params\n",
      "36.669    Total estimated model params size (MB)\n",
      "396       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  87%|████████▋ | 20/23 [00:03<00:00,  5.51it/s, train_loss=0.112]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from darts import TimeSeries\n",
    "from darts.models import NBEATSModel\n",
    "from darts.dataprocessing.transformers import Scaler, MissingValuesFiller\n",
    "from darts.metrics import smape\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Fetch data (same as before)\n",
    "# Fetch data (production endpoint)\n",
    "url = \"https://api.terminal.binbot.in/charts/adr-series?size=400\"\n",
    "data = requests.get(url).json()\n",
    "df = pd.DataFrame(data[\"data\"])\n",
    "\n",
    "# Clean and preprocess\n",
    "# Use only columns required for inference\n",
    "# (Assumes columns: timestamp, advancers, decliners, total_volume)\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "# Round timestamps to the nearest hour\n",
    "df[\"timestamp\"] = df[\"timestamp\"].dt.floor(\"h\")\n",
    "\n",
    "# Clean up missing values\n",
    "df = df.dropna()\n",
    "df = df[(df != 0).all(axis=1)]\n",
    "df = df.iloc[1:]\n",
    "if df.isnull().values.any():\n",
    "    df = df.interpolate()\n",
    "df.set_index(\"timestamp\", inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "df = df[~df.index.duplicated(keep=\"last\")]\n",
    "\n",
    "# Feature engineering\n",
    "df[\"advancers\"] = df[\"advancers\"].astype(\"float32\")\n",
    "df[\"decliners\"] = df[\"decliners\"].astype(\"float32\")\n",
    "df[\"total_volume\"] = df[\"total_volume\"].astype(\"float32\")\n",
    "df[\"adp\"] = df[\"adp\"].astype(\"float32\")\n",
    "df[\"adp_ma\"] = df[\"adp_ma\"].astype(\"float32\")\n",
    "\n",
    "# Add moving averages if required by the model\n",
    "df[\"adp_ma7\"] = df[\"adp\"].rolling(7).mean().astype(\"float32\")\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Convert to Darts TimeSeries (let Darts infer frequency)\n",
    "series = TimeSeries.from_dataframe(df, value_cols=[\"adp\"], fill_missing_dates=True, freq=\"h\")\n",
    "covariate_series = TimeSeries.from_dataframe(\n",
    "    df,\n",
    "    value_cols=[\"total_volume\", \"adp_ma\", \"adp_ma7\"],\n",
    "    fill_missing_dates=True, freq=\"h\"\n",
    ")\n",
    "\n",
    "# Fill missing values for both series and covariate series\n",
    "filler = MissingValuesFiller()\n",
    "series_filled = filler.transform(series, method=\"linear\")\n",
    "covariate_series_filled = filler.transform(covariate_series, method=\"linear\")\n",
    "\n",
    "# Z-score normalization for both series and covariate series\n",
    "scaler_series = Scaler()\n",
    "scaler_covariate = Scaler()\n",
    "series_scaled = scaler_series.fit_transform(series_filled)\n",
    "covariate_series_scaled = scaler_covariate.fit_transform(covariate_series_filled)\n",
    "\n",
    "# Parameters\n",
    "input_chunk_length = 100\n",
    "forecast_horizon = 24\n",
    "\n",
    "# Train/validation split for both series and covariate series\n",
    "train_scaled, val_scaled = (\n",
    "    series_scaled[:-forecast_horizon],\n",
    "    series_scaled[-forecast_horizon:],\n",
    ")\n",
    "train_orig, val_orig = (\n",
    "    series_filled[:-forecast_horizon],\n",
    "    series_filled[-forecast_horizon:],\n",
    ")\n",
    "train_covariate_scaled = covariate_series_scaled[:-forecast_horizon]\n",
    "\n",
    "# Define N-BEATS model with future covariates\n",
    "model = NBEATSModel(\n",
    "    input_chunk_length=input_chunk_length,\n",
    "    output_chunk_length=forecast_horizon,\n",
    "    n_epochs=10,\n",
    "    batch_size=16,\n",
    "    random_state=42,\n",
    "    optimizer_cls=optim.AdamW,\n",
    "    optimizer_kwargs={\"lr\": 1e-4},\n",
    "    lr_scheduler_cls=ReduceLROnPlateau,\n",
    "    lr_scheduler_kwargs={\"patience\": 15, \"factor\": 0.5, \"monitor\": \"train_loss\"},\n",
    ")\n",
    "\n",
    "# Fit model with future covariates\n",
    "model.fit(train_scaled, past_covariates=covariate_series_scaled, verbose=True)\n",
    "\n",
    "# Forecast beyond training data using the last available covariate window\n",
    "future_covariates = covariate_series_scaled[\n",
    "    -(input_chunk_length + forecast_horizon) :\n",
    "]\n",
    "\n",
    "future_forecast_scaled = model.predict(\n",
    "    n=forecast_horizon, past_covariates=future_covariates\n",
    ")\n",
    "\n",
    "# Convert forecast to original scale\n",
    "future_forecast_orig = scaler_series.inverse_transform(future_forecast_scaled)\n",
    "\n",
    "# Extract the corresponding portion of actual series for validation\n",
    "val_orig = series_filled[-forecast_horizon:]\n",
    "\n",
    "# Evaluation (using the original scale validation data)\n",
    "print(\"SMAPE on validation set:\", smape(val_orig, future_forecast_orig))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot actual normalized ADR for training and validation periods\n",
    "train_orig.plot(label=\"Actual ADR (Training)\", lw=2, color=\"black\")\n",
    "val_orig.plot(label=\"Actual ADR (Validation)\", lw=2, color=\"gray\")\n",
    "\n",
    "# Plot forecast extending from the end of the training data\n",
    "future_forecast_orig.plot(label=\"Forecasted ADR (with Covariates)\", lw=2, color=\"blue\")\n",
    "\n",
    "# Save model in compressed (zip) format\n",
    "model.save(\"../checkpoints/market_breadth_nbeats_model_v1.pth\")\n",
    "\n",
    "plt.title(\"N-BEATS Forecast: Normalized ADR (Z-score) with Total Volume Covariate\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c74bc0b",
   "metadata": {},
   "source": [
    "# Production Inference: Predict Market Breadth with N-BEATS\n",
    "\n",
    "This notebook cell is for production use only. It loads a pre-trained N-BEATS model, preprocesses new data, and outputs the latest forecast. All training and experimentation code has been removed.\n",
    "\n",
    "- Load model\n",
    "- Preprocess data\n",
    "- Predict\n",
    "- Output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f93da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/carkod/binbot-notebooks/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 18.31it/s]\n",
      "Latest forecasted adp: 0.38211504\n",
      "\n",
      "Latest forecasted adp: 0.38211504\n"
     ]
    }
   ],
   "source": [
    "# Production prediction script for N-BEATS model with covariates\n",
    "import pandas as pd\n",
    "import requests\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler, MissingValuesFiller\n",
    "from darts.models import NBEATSModel\n",
    "\n",
    "# Load the saved model\n",
    "model = NBEATSModel.load(\"../checkpoints/market_breadth_nbeats_model_v1.pth\")\n",
    "\n",
    "# Fetch data (production endpoint)\n",
    "url = \"https://api.terminal.binbot.in/charts/adr-series?size=700\"\n",
    "data = requests.get(url).json()\n",
    "df = pd.DataFrame(data[\"data\"])\n",
    "\n",
    "# Clean and preprocess\n",
    "# Use only columns required for inference\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "# Floor all timestamps to the nearest hour to match model training\n",
    "df[\"timestamp\"] = df[\"timestamp\"].dt.floor(\"h\")\n",
    "# Clean up missing values\n",
    "df = df.dropna()\n",
    "df = df[(df != 0).all(axis=1)]\n",
    "df = df.iloc[1:]\n",
    "if df.isnull().values.any():\n",
    "    df = df.interpolate()\n",
    "df.set_index(\"timestamp\", inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "# Remove duplicate timestamps, keeping the last occurrence\n",
    "df = df[~df.index.duplicated(keep='last')]\n",
    "\n",
    "# Feature engineering\n",
    "df[\"diff\"] = (df[\"advancers\"] - df[\"decliners\"]).astype(\"float32\")\n",
    "df[\"advancers\"] = df[\"advancers\"].astype(\"float32\")\n",
    "df[\"decliners\"] = df[\"decliners\"].astype(\"float32\")\n",
    "df[\"total_volume\"] = df[\"total_volume\"].astype(\"float32\")\n",
    "\n",
    "# Calculate normalized AD diff\n",
    "df[\"adp\"] = (df[\"diff\"] / (df[\"advancers\"] + df[\"decliners\"])).astype(\"float32\")\n",
    "\n",
    "# Add moving averages if required by the model\n",
    "df[\"adp_ma\"] = df[\"adp_ma\"].astype(\"float32\")\n",
    "df[\"adp_ma7\"] = (df[\"adp\"].rolling(7).mean()).astype(\"float32\")\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# --- Extend covariates into the future ---\n",
    "input_chunk_length = 240\n",
    "forecast_horizon = 72\n",
    "\n",
    "# Create a future index for the forecast horizon\n",
    "last_timestamp = df.index[-1]\n",
    "future_index = pd.date_range(start=last_timestamp + pd.Timedelta(1, unit='h'), periods=forecast_horizon, freq=\"h\")\n",
    "\n",
    "# Forward-fill the last row for covariates\n",
    "future_covariates_df = pd.DataFrame(\n",
    "    [df.iloc[-1][[\"total_volume\", \"adp_ma\", \"adp_ma7\"]].values] * forecast_horizon,\n",
    "    columns=[\"total_volume\", \"adp_ma\", \"adp_ma7\"],\n",
    "    index=future_index\n",
    ")\n",
    "\n",
    "# Append to the original DataFrame for covariates\n",
    "covariate_df_full = pd.concat([\n",
    "    df[[\"total_volume\", \"adp_ma\", \"adp_ma7\"]],\n",
    "    future_covariates_df\n",
    "])\n",
    "\n",
    "# Create TimeSeries for target and covariates\n",
    "covariate_series = TimeSeries.from_dataframe(\n",
    "    covariate_df_full,\n",
    "    value_cols=[\"total_volume\", \"adp_ma\", \"adp_ma7\"],\n",
    "    fill_missing_dates=True, freq=\"h\"\n",
    ")\n",
    "\n",
    "# Fill missing values\n",
    "filler = MissingValuesFiller()\n",
    "covariate_series_filled = filler.transform(covariate_series, method=\"linear\")\n",
    "\n",
    "# Z-score normalization (fit on all available data)\n",
    "scaler_series = Scaler()\n",
    "scaler_covariate = Scaler()\n",
    "\n",
    "# Fit scaler_series on the target series (adp)\n",
    "series_for_scaling = TimeSeries.from_dataframe(df, value_cols=[\"adp\"], fill_missing_dates=True, freq=\"h\")\n",
    "series_for_scaling_filled = filler.transform(series_for_scaling, method=\"linear\")\n",
    "scaler_series.fit(series_for_scaling_filled)\n",
    "\n",
    "covariate_series_scaled = scaler_covariate.fit_transform(covariate_series_filled)\n",
    "\n",
    "# Use the latest available covariates for prediction\n",
    "future_covariates = covariate_series_scaled[-(input_chunk_length + forecast_horizon):]\n",
    "\n",
    "# Predict\n",
    "y_pred_scaled = model.predict(n=forecast_horizon, past_covariates=future_covariates)\n",
    "y_pred = scaler_series.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Output forecast as DataFrame\n",
    "forecast_df = y_pred.to_dataframe()\n",
    "latest_prediction = forecast_df.iloc[-1][\"adp\"]\n",
    "print(\"Latest forecasted adp:\", latest_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
